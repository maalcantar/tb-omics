{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import collections\n",
    "import pandas as pd\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sns.set_style('white')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1500)\n",
    "\n",
    "#set for reproducibility\n",
    "os.chdir('.\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metabolomics(filename):\n",
    "    \n",
    "    # loading in TB plasma metabolomics data from tab-delimted file to pandas dataframe\n",
    "    df = pd.read_csv(filename)#, sep='\\t', lineterminator='\\r') # loading data\n",
    "    df = df.rename(columns={df.columns.values[0]: 'metabolite_name'})\n",
    "    #df['metabolite_name'] = df['metabolite_name'].str.strip('\\n') # getting rid of line-terminator\n",
    "    \n",
    "    df = df.transpose()\n",
    "    df.columns = df.iloc[0, :]\n",
    "    df = df.iloc[1:, :]#df.index.name = 'local_sample_id'\n",
    "    df.index.name = 'sample_id' #= df.rename(columns={'metabolite_name': 'local_sample_id'})\n",
    "    #df = df.rename_axis(None)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df, thresh=0.1):\n",
    "    null_allowed = len(df.index) * thresh\n",
    "    null_columns = df.columns.values[df.isnull().sum() > null_allowed]\n",
    "    \n",
    "    df = df.drop(columns = null_columns) \n",
    "    #TODO: drop null columns rather than any with empty valus, impute with minimum value\n",
    "    \n",
    "    return df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patientmetadata(filename, m_df):\n",
    "    # reading in patient metadata\n",
    "    p_df = pd.read_csv(filename)\n",
    "    p_df.columns = p_df.columns.str.lower()\n",
    "    p_df = p_df.set_index('sample_id')\n",
    "    #drop redundant columns\n",
    "    p_df = p_df.drop(columns=[p_df.columns.values[0], 'id'])\n",
    "    #join with full dataset\n",
    "    m_df = m_df.set_index('sample_id').join(p_df)\n",
    "\n",
    "    return m_df.reset_index(), p_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing data by making values (features) zero-mean and unit-variance\n",
    "def standardize_data(f_vals):\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    # applying standardization \n",
    "    standardizerScaler = preprocessing.StandardScaler()\n",
    "    data_StandardScaled = standardizerScaler.fit_transform(f_vals)\n",
    "    \n",
    "    return data_StandardScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(f_vals, features, l_vals, labels):\n",
    "    df = pd.concat([pd.DataFrame(data=l_vals, columns=labels), \n",
    "                    pd.DataFrame(data=f_vals, columns=features)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_PCA(data, l_vals, labels, save=False, ncomp=10):\n",
    "# computing principal components\n",
    "    from sklearn import decomposition\n",
    "\n",
    "    pcaAbs = decomposition.PCA(n_components=ncomp)\n",
    "    data_PCA = pcaAbs.fit_transform(data)\n",
    "    \n",
    "    pc_cols = ['PC ' + str(i) for i in np.arange(1, ncomp + 1)]\n",
    "    df_PCA = make_df(data_PCA, pc_cols, l_vals, labels)\n",
    "    \n",
    "    #Plot explained variance by number of components\n",
    "    var_exp = pcaAbs.explained_variance_ratio_\n",
    "    fig_ve, ax_ve = plt.subplots(1, 1)\n",
    "    sns.lineplot(x=(np.arange(len(var_exp)) + 1), y=np.cumsum(var_exp), ax=ax_ve)\n",
    "    plt.xlabel('PCA component number')\n",
    "    plt.ylabel('Cumulative variance ratio')\n",
    "    if save:\n",
    "        plt.savefig('variance-exp.png', bbox_inches='tight', pad_inches=0.5)\n",
    "    \n",
    "    fig_pca, ax_pca = plt.subplots(1, 1)\n",
    "    sns.scatterplot(x='PC 1', y='PC 2', data=df_PCA, hue='group', ax=ax_pca)\n",
    "    \n",
    "    return df_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plasma_df = load_metabolomics('measurements_plasma_full.csv')\n",
    "serum_df  = load_metabolomics('measurements_serum_full.csv')\n",
    "rpmi_df   = load_metabolomics('measurements_plasmarpmi_full.csv')\n",
    "\n",
    "full_df   = pd.concat([plasma_df, serum_df, rpmi_df], sort=False).reset_index()\n",
    "full_df, patient_df = load_patientmetadata('full_unblinded_metadata_with_smoking_tst.csv', full_df)\n",
    "#metabolomicsTB_df = impute(metabolomicsTB_df)\n",
    "\n",
    "# displaying shape and first few data entries\n",
    "print('The shape of our data matrix is: ', full_df.shape)\n",
    "#metabolomicsTB_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['group', 'mb_sample_id', 'timepoint', 'region', 'gender']\n",
    "features = [x for x in metabolomicsTB_df.columns.to_list() if x not in labels]\n",
    "f_vals = metabolomicsTB_df.loc[:, features].values\n",
    "l_vals = metabolomicsTB_df.loc[:, labels].values\n",
    "\n",
    "\n",
    "std_data = standardize_data(f_vals)\n",
    "std_df = make_df(std_data, features, l_vals, labels)\n",
    "# displaying shape and first few data entries\n",
    "print('The shape of the standardized data is:', std_df.shape)\n",
    "#display(std_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "males_data = std_data[ std_df['timepoint'].str.contains('M')]\n",
    "males_labels = l_vals[ std_df['timepoint'].str.contains('M')]\n",
    "pca_df = perform_PCA(males_data, males_labels, labels, save=False, ncomp=10)\n",
    "display(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolites = list(metabolomicsTB_df.columns)[:-1]\n",
    "numMetabas = metabolomicsTB_df.shape[1] - 1\n",
    "alpha = 0.05\n",
    "\n",
    "significant = []\n",
    "for metab in metabolites:\n",
    "    indicesControl = metabolomicsTB_df['group'] == 'control'\n",
    "    indicesCase = metabolomicsTB_df['group'] == 'case'\n",
    "    \n",
    "    metabAverageControl = list(metabolomicsTB_df.loc[indicesControl, metab])\n",
    "    metabAverageCase = list(metabolomicsTB_df.loc[indicesCase, metab])\n",
    "    stat, p_val = sp.stats.ranksums(metabAverageControl, metabAverageCase)\n",
    "    \n",
    "    if p_val  < alpha / numMetabas:\n",
    "        significant.append(metab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do Spearman correlation for healthy vs. disease\n",
    "display(metabolomicsTB_df.sort_values(by=['timepoint', 'group']))\n",
    "#df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('.\\data')\n",
    "ut_file = os.path.join('.\\data\\met_data', 'ST000974_AN001595_res.txt')\n",
    "ut_met = pd.read_csv(ut_file, sep='\\t', lineterminator='\\r')\n",
    "ut_met['Samples'] = ut_met['Samples'].str.strip('\\n')\n",
    "metadata = ut_met['group'].str.rsplit(' | ', expand=True)\n",
    "cols = metadata.iloc[0, :].str.rsplit(':', expand=True)[0].str.lower()\n",
    "metadata.columns = cols\n",
    "metadata = metadata.apply(lambda x: x.str.rsplit(':', expand=True)[1])\n",
    "\n",
    "ut_met = ut_met.drop(columns='group')\n",
    "ut_met = ut_met.join(metadata)\n",
    "ut_met.dropna(axis=0)\n",
    "#display(metadata)\n",
    "#display(ut_met)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut_met.columns = (ut_met.columns.str.lstrip('X - ')\n",
    "                                .str.lstrip('0')\n",
    "                                .str.lower())\n",
    "ut_met = ut_met.fillna(ut_met.min())  #impute missing values as = limit of detection\n",
    "ut_met.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['samples', 'timepoint', 'region', 'gender']\n",
    "mz = [x for x in ut_met.columns.to_list() if x not in labels]\n",
    "ut_mz = ut_met[mz]\n",
    "ut_met_summary = ut_mz.groupby(['group']).agg([('Mean', np.nanmean), ('Std', np.nanstd)])\n",
    "display(ut_met_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolites = mz[:-1]\n",
    "#print(metabolites)\n",
    "numMetabas = len(mz)\n",
    "alpha_diff = 0.05\n",
    "alpha_normal = 0.05\n",
    "significant = []\n",
    "for metab in metabolites:\n",
    "    indicesControl = np.array(ut_met['group'] == 'control') * np.array(ut_met['timepoint'] != 'BL')\n",
    "    indicesCase = np.array(ut_met['group'] == 'case') * np.array(ut_met['timepoint'] != 'BL')\n",
    "    \n",
    "    \n",
    "    metabAverageControl = list(ut_met.loc[indicesControl, metab])\n",
    "    metabAverageCase = list(ut_met.loc[indicesCase, metab])\n",
    "    \n",
    "    \n",
    "    _, p_normal_ctrl = sp.stats.normaltest(metabAverageControl, nan_policy='omit')\n",
    "    _, p_normal_case = sp.stats.normaltest(metabAverageCase, nan_policy='omit')\n",
    "    #print(metab, p_normal_ctrl, p_normal_case)\n",
    "    \n",
    "    if (p_normal_ctrl < alpha_normal and p_normal_case < alpha_normal):\n",
    "        _, p_var = sp.stats.bartlett(metabAverageControl, metabAverageCase)\n",
    "        _, p_diff = sp.stats.ttest_ind(metabAverageControl, metabAverageCase, nan_policy='omit', equal_var=(p_var<alpha_normal))\n",
    "    else:\n",
    "        _, p_diff = sp.stats.ranksums(metabAverageControl, metabAverageCase)\n",
    "    \n",
    "    if p_diff  < alpha_diff:\n",
    "        significant.append(float(metab))\n",
    "        \n",
    "#print(significant)\n",
    "significant = pd.DataFrame({'mz' : significant})\n",
    "display(significant)\n",
    "\n",
    "significant.to_csv('significant_mz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ADAPTED FROM CDUVALLET\n",
    "#positive ion mode\n",
    "def calculate_adducts(mzs):\n",
    "    m = {'C': 12.0,\n",
    "         'H': 1.007825,\n",
    "         'O': 15.994915,\n",
    "         'N': 14.003074,\n",
    "         'S': 31.972072,\n",
    "         'Cl': 34.968853,\n",
    "         'F': 18.998403,\n",
    "         'B': 10.012938,\n",
    "         'D': 2.014102,\n",
    "         'Na': 22.989770,\n",
    "         'K' : 39.0983, \n",
    "         'e-': 0.000548579909}\n",
    "    \n",
    "    plush = [(float(i) - m['H']) for i in mzs]\n",
    "    plusnh4 = [(float(i) - (m['N'] + 4 * m['H'])) for i in mzs] \n",
    "    plush2o = [(float(i) - (2 * m['H'] + m['O'])) for i in mzs]\n",
    "    plusna = [(float(i) - m['Na']) for i in mzs]\n",
    "    plusk = [(float(i) - m['K']) for i in mzs]\n",
    "    plusch3cn = [(float(i) - (2 * m['C'] + 3 * m['H'] + m['N'])) for i in mzs]\n",
    "    return plush, plusnh, plush2o, plusna, plusk, plusch3cn\n",
    "\n",
    "def parse_HMDB(xml_file):\n",
    "    from lxml import etree\n",
    "    ## ADAPTED FROM CDUVALLET\n",
    "    outdict = {}\n",
    "    tree = etree.iterparse(xml_file, tag='metabolite')\n",
    "    counter = 0\n",
    "\n",
    "    for event, elem in tree:\n",
    "        counter += 1\n",
    "        if counter % 2000 == 0:\n",
    "            print('Reading {}th metabolite from HMDB'.format(counter))\n",
    "        tmpdict = {}\n",
    "        tmpdict['name'] = elem.findtext('name')\n",
    "        if elem.findtext('monisotopic_moleculate_weight'):\n",
    "            tmpdict['neutral_mass'] = elem.findtext('monisotopic_moleculate_weight')\n",
    "        else:\n",
    "            tmpdict['neutral_mass'] = '0.0'\n",
    "\n",
    "        outdict[elem.findtext('accession')] = tmpdict\n",
    "        elem.clear()\n",
    "    return outdict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = os.path.join('.\\data\\met_data', 'cleaned_serum_metabolites.xml')\n",
    "outdict = parse_HMDB(xml_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
