{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import collections\n",
    "import pandas as pd\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sns.set_style('white')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1500)\n",
    "\n",
    "#set for reproducibility\n",
    "os.chdir('.\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metabolomics(filename):\n",
    "    # loading in TB plasma metabolomics data from tab-delimted file to pandas dataframe\n",
    "    df = pd.read_csv(filename)#, sep='\\t', lineterminator='\\r') # loading data\n",
    "    df = df.rename(columns={df.columns.values[0]: 'metabolite_name'})\n",
    "    #df['metabolite_name'] = df['metabolite_name'].str.strip('\\n') # getting rid of line-terminator\n",
    "    \n",
    "    df = df.transpose()\n",
    "    df.columns = df.iloc[0, :]\n",
    "    df = df.iloc[1:, :]#df.index.name = 'local_sample_id'\n",
    "    df.index.name = 'sample_id' #= df.rename(columns={'metabolite_name': 'local_sample_id'})\n",
    "    #df = df.rename_axis(None)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df, thresh=0.1):\n",
    "    #drop columns with proportion missing values > threshold\n",
    "    null_allowed = len(df.index) * thresh\n",
    "    null_columns = df.columns.values[df.isnull().sum() > null_allowed]\n",
    "    df = df.drop(columns=null_columns) \n",
    "    #impute remaining nans with minimum value\n",
    "    df = df.apply(lambda x: x.fillna(x.min()), axis=0)\n",
    "    return df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patientmetadata(filename, m_df):\n",
    "    # reading in patient metadata\n",
    "    p_df = pd.read_csv(filename)\n",
    "    p_df.columns = p_df.columns.str.lower()\n",
    "    p_df = p_df.set_index('sample_id')\n",
    "    #drop redundant columns\n",
    "    p_df = p_df.drop(columns=[p_df.columns.values[0], 'id'])\n",
    "    #join with full dataset\n",
    "    m_df = m_df.set_index('sample_id').join(p_df)\n",
    "\n",
    "    return m_df.reset_index(), p_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing data by making values (features) zero-mean and unit-variance\n",
    "def standardize_data(f_vals):\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    # applying standardization \n",
    "    standardizerScaler = preprocessing.StandardScaler()\n",
    "    data_StandardScaled = standardizerScaler.fit_transform(f_vals)\n",
    "    \n",
    "    return data_StandardScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(f_vals, features, l_vals, labels):\n",
    "    df = pd.concat([pd.DataFrame(data=l_vals, columns=labels), \n",
    "                    pd.DataFrame(data=f_vals, columns=features)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_PCA(data, l_vals, labels, save=False, ncomp=10):\n",
    "# computing principal components\n",
    "    from sklearn import decomposition\n",
    "\n",
    "    pcaAbs = decomposition.PCA(n_components=ncomp)\n",
    "    data_PCA = pcaAbs.fit_transform(data)\n",
    "    \n",
    "    pc_cols = ['PC ' + str(i) for i in np.arange(1, ncomp + 1)]\n",
    "    df_PCA = make_df(data_PCA, pc_cols, l_vals, labels)\n",
    "    \n",
    "    #Plot explained variance by number of components\n",
    "    var_exp = pcaAbs.explained_variance_ratio_\n",
    "    fig_ve, ax_ve = plt.subplots(1, 1)\n",
    "    sns.lineplot(x=(np.arange(len(var_exp)) + 1), y=np.cumsum(var_exp), ax=ax_ve)\n",
    "    plt.xlabel('PCA component number')\n",
    "    plt.ylabel('Cumulative variance ratio')\n",
    "    if save:\n",
    "        plt.savefig('variance-exp.png', bbox_inches='tight', pad_inches=0.5)\n",
    "    \n",
    "    fig_pca, ax_pca = plt.subplots(1, 1)\n",
    "    sns.scatterplot(x='PC 1', y='PC 2', data=df_PCA, hue='group', ax=ax_pca)\n",
    "    \n",
    "    return df_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significanceTest(ctrl, case):\n",
    "    _, p_normal_ctrl = sp.stats.normaltest(ctrl, nan_policy='omit')\n",
    "    _, p_normal_case = sp.stats.normaltest(case, nan_policy='omit')\n",
    "    #print(metab, p_normal_ctrl, p_normal_case)\n",
    "    \n",
    "    if (p_normal_ctrl < alpha_normal and p_normal_case < alpha_normal):\n",
    "        _, p_var = sp.stats.bartlett(ctrl, case)\n",
    "        _, p_diff = sp.stats.ttest_ind(ctrl, case, nan_policy='omit', equal_var=(p_var < alpha_normal))\n",
    "    else:\n",
    "        _, p_diff = sp.stats.ranksums(ctrl, case)\n",
    "    \n",
    "    return p_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = ['measurements_plasma_full.csv', 'measurements_serum_full.csv', 'measurements_plasmarpmi_full.csv']\n",
    "all_df = []\n",
    "for file in all_files:\n",
    "    temp_df = impute(load_metabolomics(file))\n",
    "    index = temp_df.index\n",
    "    temp_df = pd.DataFrame(data=standardize_data(temp_df), columns=temp_df.columns)\n",
    "    temp_df.index = index\n",
    "    all_df.append(temp_df)\n",
    "    \n",
    "full_df   = pd.concat(all_df, sort=False).reset_index()\n",
    "full_df, patient_df = load_patientmetadata('full_unblinded_metadata_with_smoking_tst.csv', full_df)\n",
    "\n",
    "labels = list(patient_df)#['group', 'mb_sample_id', 'timepoint', 'region', 'gender']\n",
    "features = [x for x in full_df.columns.to_list() if x not in labels]\n",
    "f_vals = full_df.loc[:, features].values\n",
    "l_vals = full_df.loc[:, labels].values\n",
    "\n",
    "# displaying shape and first few data entries\n",
    "print('The shape of our data matrix is: ', full_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolites = list(metabolomicsTB_df.columns)[:-1]\n",
    "numMetabas = metabolomicsTB_df.shape[1] - 1\n",
    "alpha = 0.05\n",
    "\n",
    "significant = []\n",
    "for metab in metabolites:\n",
    "    indicesControl = metabolomicsTB_df['group'] == 'control'\n",
    "    indicesCase = metabolomicsTB_df['group'] == 'case'\n",
    "    \n",
    "    metabAverageControl = list(metabolomicsTB_df.loc[indicesControl, metab])\n",
    "    metabAverageCase = list(metabolomicsTB_df.loc[indicesCase, metab])\n",
    "    stat, p_val = sp.stats.ranksums(metabAverageControl, metabAverageCase)\n",
    "    \n",
    "    if p_val  < alpha / numMetabas:\n",
    "        significant.append(metab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do Spearman correlation for healthy vs. disease\n",
    "display(metabolomicsTB_df.sort_values(by=['timepoint', 'group']))\n",
    "#df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut_met_summary = ut_mz.groupby(['group']).agg([('Mean', np.nanmean), ('Std', np.nanstd)])\n",
    "display(ut_met_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plasma_df = full_df[full_df['sample_type'].str.contains('plasma')]\n",
    "plasma_df.head()\n",
    "metabolites = [x for x in plasma_df.columns.to_list() if x not in labels]\n",
    "metabolites = metabolites[:-1]\n",
    "#print(metabolites)\n",
    "alpha_diff = 0.01\n",
    "alpha_normal = 0.05\n",
    "significant = []\n",
    "for metab in metabolites:\n",
    "    indicesControl = np.array(plasma_df['group'] == 'control') * np.array(plasma_df['timepoint'] != 'BL')\n",
    "    indicesCase = np.array(plasma_df['group'] == 'case') * np.array(plasma_df['timepoint'] != 'BL')\n",
    "    \n",
    "    \n",
    "    metabAverageControl = list(plasma_df.loc[indicesControl, metab])\n",
    "    metabAverageCase = list(plasma_df.loc[indicesCase, metab])\n",
    "    \n",
    "    p_diff = significanceTest(metabAverageControl, metabAverageCase)\n",
    "    if p_diff  < alpha_diff:\n",
    "        significant.append(metab)\n",
    "        \n",
    "#print(significant)\n",
    "significant = pd.DataFrame({'metabolite' : significant})\n",
    "display(significant)\n",
    "\n",
    "#significant.to_csv('significant_metabolite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plasma_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
